[
  {
    "objectID": "scripts/BYOD1_workshop.html#packages",
    "href": "scripts/BYOD1_workshop.html#packages",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "3.1 Packages",
    "text": "3.1 Packages\nIn this section, we will learn about the different packages that we will be using in this workshop and will explore different functions for reading files into r.\n\n\n\nEssential R packages for tidying and visualizing data\n\n\nPackage\nPurpose\n\n\n\n\nreadr\nRead delimited files\n\n\nreadxl\nRead excel files\n\n\ntidyr\nTidy messy data\n\n\ndplyr\nFormat and summarize data tables\n\n\nstringr\nFormat character strings\n\n\njanitor\nMore data cleaning (not in the tidyverse)\n\n\nggplot2\nCreate elegant data visualisations using the grammar of graphics\n\n\ntidyverse\nLoad many of the packages in the tidyverse\n\n\n\n\n\nLet’s load packages!\n\n# load packages in the tidyverse (e.g., readr, readxl, tidyr)\nlibrary(tidyverse) \nlibrary(readxl)\n\n# we can check what packages were loaded\nnames(sessionInfo()[[\"otherPkgs\"]])"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#loading-data",
    "href": "scripts/BYOD1_workshop.html#loading-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "3.2 Loading data",
    "text": "3.2 Loading data\nLet’s load a few datasets in different formats. First, you’ll need to download the data to your computer and save it in a folder called “data” that’s inside of your RStudio project.\npenguin_data_final.xlsx\nSince we stored the data inside a folder in the project, the file path is very simple. If you need to load data that is stored outside the project, you will need to specify the whole file path.\n\n# load a .xlsx file into your R environment\nmydat_xls &lt;- read_excel(\"data/penguin_data_final.xlsx\") \n\nNext, let’s try loading data from a url. We would use the read_csv function for data on our computer as well.\n\n# load a .csv file into your R environment\nmydat_csv &lt;- read_csv(\"https://raw.githubusercontent.com/MN-DNR-R/BYOD_Seminar1_Data_Summaries_and_Visualization/refs/heads/main/data/penguin_data_final.csv?token=GHSAT0AAAAAADGVPTNKVJGII66G3RODGYUA2JGFBOA\") \n\nA summary of the data is generated when you use the “read_” functions. You can also look in the environment and make sure that the files were loaded properly! We will also demonstrate ways to explore your data in the next section."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#data-from-a-package",
    "href": "scripts/BYOD1_workshop.html#data-from-a-package",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "3.3 Data from a package",
    "text": "3.3 Data from a package\nSome datasets are stored inside of R packages. We will use one that’s in a package for the rest of our demonstration.\nThe palmerpenguins package was created by Allison Horst, Alison Hill, and Kristen Gorman as a tool for teaching data manipulation and analysis techniques in R. In the following sections we will explore the data available within this package, and we will learn to manipulate and visualize the data using a variety of tools and techniques. Below you will use the citation() command line to get the full citation for the package!\nThe library contains two datasets which can be called without having to read them manually (as we previously did with the .csv or .xlsx files). One which contains raw penguins data (penguin_raw), and the second file (penguins) is the simplified (i.e., clean) dataset.\nYou also can read more about the package here: PalmerPenguins\n\n# install package (delete the '#' to run the line and use the '#' after you've installed the package)\n# install.packages(\"palmerpenguins\")\n\n# load library into your R environment \nlibrary(palmerpenguins)\n\n# get information about the package:\n?palmerpenguins\n\n# Get proper citation for the package (e.g., to use in a publication). Note that you can use the \"citation\" function for any of the packages used in an analysis, which is very useful when writing the methods in a report or peer-reviewed manuscript. \ncitation(\"palmerpenguins\")\n\n# let's save the raw data in our environment\nrawdat &lt;- penguins_raw"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#data-exploration-functions",
    "href": "scripts/BYOD1_workshop.html#data-exploration-functions",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.1 Data exploration functions",
    "text": "4.1 Data exploration functions\nThere are many functions available to explore the data. Here is a list of the main ones that we will be using in this workshop.\n\n\n\nUseful functions for data exploration\n\n\nFunction\nPurpose\n\n\n\n\nglimpse()\nOverview of dataframe rows, columns, column names, dataframe dimension, and a glimpse of first values\n\n\nstr()\nSuccinct summary of all columns of a dataframe; similar to glimpse but within base R\n\n\nnames()\nColumn names\n\n\nhead()\nDisplay first n rows of data (default is 6)\n\n\ntail()\nDisplays last n rows of data (default is 6)\n\n\nnrow()\nNumber of rows\n\n\nncol()\nNumber of columns\n\n\nsummary()\nSummary of the data in each column\n\n\nunique()\nDisplays unique values of a variable"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#data-types",
    "href": "scripts/BYOD1_workshop.html#data-types",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.2 Data types",
    "text": "4.2 Data types\nBefore doing any data manipulation in R, it is important to recognize the different data types. When importing your data into R, R will automatically recognize the type of data of each column. At times, however, a specific data type may need to be set or converted from one to another.\nFor example, one could use the as.numeric() function to convert a column to numeric, or as.character() to convert to character. When doing such data conversions, it is important to note that some elements of a vector may be converted to NAs if R recognizes that it does not correspond to the data type specified.\nA good example of this is when a column that should be numeric contains characters (e.g., instead of an actual count one had recorded something like “more then 100 animals”). In this case, this would return an “NA” as R does not know what to do with this information! Good data entry and quality checks prior to importing data into R are very important to help prevent data loss.\nWith a factor data type, you can specify the order of variables, such as “low”, “medium”, “high”. This defined order can then make data visualizations and analyses more intuitive.\n\n\n\nData types supported in R\n\n\nType\nExample\n\n\n\n\nNumeric\n1.5, 2.6\n\n\nInteger\n1, 2\n\n\nLogical\nTrue/False\n\n\nCharacter\nOne, Two\n\n\nFactor\nControl, Treatment"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#examining-the-data",
    "href": "scripts/BYOD1_workshop.html#examining-the-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.3 Examining the data",
    "text": "4.3 Examining the data\nLet’s use the functions from the function description table above to examine what is contained in our dataset.\n\n# the glimpse function provides a good first overview of the data\nglimpse(rawdat)\n\n# the str function also provides a quick but complete overview of the structure of the data\nstr(rawdat)\n\n# quick summary of all of the data\nsummary(rawdat)\n\n# print column names\nnames(rawdat)\n\n# look at first and last rows\nhead(rawdat, n = 10)\ntail(rawdat, n = 10)\n\n# number of rows and columns\nnrow(rawdat)\nncol(rawdat)\n\n# lists unique values (this can help identify if there are data entry errors)\nunique(rawdat$Species)\nunique(rawdat$Island)\nunique(rawdat$Region)\n\n# How many unique ID's do we have? How many data points do we have? Do they match?\nunique(rawdat$`Individual ID`)"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#data-quality-check",
    "href": "scripts/BYOD1_workshop.html#data-quality-check",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.4 Data quality check",
    "text": "4.4 Data quality check\nLooking at the raw data, what could be improved for analyses and data visualizations? Is the dataset pretty clean and analysis-ready, or are these things that need to be addressed and changed so that we don’t run into issues later in the process?\nHere are some examples:\n\nnames in the Species column are long\nthe Sex and Stage columns are characters, but they would be more useful as factors\n\nExercise: Can you think of any others?"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#what-is-tidy-data",
    "href": "scripts/BYOD1_workshop.html#what-is-tidy-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.1 What is tidy data?",
    "text": "5.1 What is tidy data?\nWe refer to “tidy data” as a dataset where each column is a variable, each row is an observation, and each cell contains a single value and a data type that is consistent across a given column (e.g., all numeric). The tidyverse packages contains functions for manipulating the data so that we can create a clean, tidy dataset to be used for all analyses.\nNote: Recall that we will never overwrite the original dataset. The raw data should always remain in its original location and be unaltered. The beauty of R scripts is that we can save all data cleaning and data manipulation steps while retaining the original data\nWhy is it important to tidy our data?\nTaking time to tidy a dataset ensures that the data summaries, analyses, or visualizations we produce represent “true” data values to the best of our knowledge (e.g., no wrongly assigned values, missing data, or data entry errors). It is a the first and most critical step of any data analysis, and though it can be a lengthy process, it is worth the effort.\nWhy tidy data in R?\nUsing R ensures that the original dataset is kept unaltered, and that all data manipulation steps are documented and reproducible. This is a major advantage of tidying data in R as opposed to using spreadsheet applications such as Excel, where there is often few to no records of changes made to a dataset."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#the-pipe-operator",
    "href": "scripts/BYOD1_workshop.html#the-pipe-operator",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.2 The pipe operator",
    "text": "5.2 The pipe operator\nR uses many different operators such as &lt;- and = along with typical arithmetic (+, -, *, /, ^) and relational (&lt;, &gt;, &lt;=, &gt;=, == ,!=) symbols. The pipe operator (%&gt;% or |&gt;) provides a way to efficiently chain functions together in a single statement. It is similar to saying: let’s take this data, and then do this with it, and then do this, kind of like a data assembly line! So ultimately, every time that you see or use %&gt;% or |&gt; in a script, you can think of it as being the same as if you were reading or coding and then…! It is a very useful tool for tidying data.\nThe operator |&gt; is from base R while %&gt;% is from the tidyverse package magrittr. More background on the origin and use of the pipe operator can be found here.\nLet’s look at an example of tidying data with and without the pipe operator.\n\n# edit the raw data to filter for samples collected from Torgersen Island and arrange the table by the date the egg was collected\n\n# without the pipe operator\ntorg1 &lt;- filter(rawdat, Island == \"Torgersen\")\ntorg2 &lt;- arrange(torg1, 'Date Egg')\n\n# with the pipe operator\ntorg &lt;- rawdat %&gt;% \n  filter(Island == \"Torgersen\") %&gt;% \n  arrange('Date Egg')\n\nWhen using the pipe operator, the input from before the pipe becomes the first argument in the function after the pipe. If you want the input to be the second, third, etc. argument, represent its location with .."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#tidy-functions",
    "href": "scripts/BYOD1_workshop.html#tidy-functions",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.3 Tidy functions",
    "text": "5.3 Tidy functions\nNow that we’ve introduced a few basic tidy data concepts and tools, we can start tidying our data. There are many very useful functions to subset data, re-arrange columns, create new columns, etc. Below are the ones you may use more frequently as you learn to tidy your data in R and with the tidyverse packages.\n\n\n\nUseful functions to create tidy data\n\n\nFunction\nPurpose\n\n\n\n\nfilter()\nKeep (or exclude) rows that meet specific criteria\n\n\nselect()\nSelect columns to keep (or to drop)\n\n\narrange()\nSort a dataframe based on a column's value (or several columns' values)\n\n\nmutate()\nAdd new columns or update existing columns\n\n\nrename()\nRename columns"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#formating-column-names",
    "href": "scripts/BYOD1_workshop.html#formating-column-names",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.4 Formating column names",
    "text": "5.4 Formating column names\nSome of the column names are difficult to work with because they have spaces and symbols. Let’s fix that.\n\n# look at the column names\nhead(rawdat)\nnames(rawdat)\n\n# let's make the following changes:\n# lowercase names\n# replace spaces with _\n# replace / with _\n# remove parentheses\nrawdat2 &lt;- rawdat %&gt;% \n  rename_with(.fn = str_to_lower) %&gt;% \n  rename_with(.fn = ~str_replace_all(.x, \" \", \"_\")) %&gt;% \n  rename_with(.fn = ~str_replace_all(.x, \"/\", \"_\")) %&gt;% \n  rename_with(.fn = ~str_remove_all(.x, \"\\\\(|\\\\)\"))\n\n# look at new names\nnames(rawdat2)\n\nThe functions str_to_lower() and str_replace_all() are part of the stringr package, automatically loaded when we load tidyverse, but it could be loaded individually as well. The function rename_with() is like rename(), but allows you to use functions within it. Use rename() if you want to do a one-to-one change in column names."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#removing-unecessary-data",
    "href": "scripts/BYOD1_workshop.html#removing-unecessary-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.5 Removing unecessary data",
    "text": "5.5 Removing unecessary data\nTo simplify the dataset, let’s remove columns and rows we don’t need. We will now rename the dataset as “cleandat” so that we maintain the raw data unaltered, and save all changes and additions into the clean dataset. The columns we select will correspond to the analyses we’re interested in. If data are missing, we may want to remove those observations from the dataset.\n\n# let's see whether all the observations have flipper length\nrawdat2 %&gt;% \n  filter(is.na(flipper_length_mm))\n\n# keep only columns of interest\n# use select to remove columns (an alternative approach)\n# remove observations (rows) missing flipper length\ncleandat1 &lt;- rawdat2 %&gt;% \n  select(individual_id, species, region, island, stage, clutch_completion, \n         date_egg, flipper_length_mm, culmen_length_mm, body_mass_g,sex, \n         comments) %&gt;% \n  select(!stage & !region) %&gt;% \n  filter(!is.na(flipper_length_mm))"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#modifying-variables",
    "href": "scripts/BYOD1_workshop.html#modifying-variables",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.6 Modifying variables",
    "text": "5.6 Modifying variables\nOften, variables that are characters need to be formatted to make them easier to use for analyses. We’ll rename the dataset again to keep the original data saved.\n\n# look at species names\nunique(cleandat1$species)\n\n# remove the scientific name\ncleandat2 &lt;- cleandat1 %&gt;% \n  mutate(species = str_remove(species, \" \\\\(Pygoscelis adeliae\\\\)\") %&gt;% \n           str_remove(\" \\\\(Pygoscelis papua\\\\)\") %&gt;% \n           str_remove(\" \\\\(Pygoscelis antarctica\\\\)\"))\n\n# look at new species names\nunique(cleandat2$species)\n\n\n5.6.1 Flagging usability of data\nIf it looks like some records may not be usable based on some criteria, it may be a good idea to create an indicator variable (yes/no) that identifies which record may not be usable for a specific analysis. If needed, we can do this using the mutate and case_when functions.\n\n# look at the comments to assess if some data may not be usable for analysis  \nunique(cleandat2$comments)\n\n# create an indicator variable for whether the sex variable is usable\ncleandat3 &lt;- cleandat2 %&gt;% \n  mutate(usable_sex_data = case_when(\n    str_detect(comments, \"No blood sample obtained\") ~ \"no\",\n    str_detect(comments, \"Sexing primers did not amplify\") ~ \"no\",\n    TRUE ~ \"yes\"))\n\n# let's see if this flag works\ncleandat3 %&gt;% \n  distinct(usable_sex_data, sex)\n\nNote: While in this example the number of unique comments to look through was relatively small and we could easily decide which ones to use for coding the “usable” columns as “yes” or “no”, in real life it is very impractical and not advised to store any critical information in a general free-form “comments” column, especially if that information pertains to the quality or usability of the data. The best practice is to maintain a metadata spreadsheet that contains all of the sampling information for a given sampling point, including comments, but that would also contain a column with a “yes” or a “no” value so that the analyst can quickly filter data without having to weed through long comments or make decisions on what they may mean. Just something to keep in mind!\n\nAt times, though, we can create a is-the-data-usable (Yes/No) column based on some variables (but not free-form comments!). For example, if one had sample-site specific wind, precipitation, temperature, time of day information, it would be easy to generate a “data quality” variable based on specific sampling conditions (e.g., if wind exceeds this, exclude this data point)."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#creating-new-variables",
    "href": "scripts/BYOD1_workshop.html#creating-new-variables",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.7 Creating new variables",
    "text": "5.7 Creating new variables\nWe’re getting close to having a dataset that will be easier to use for analysis! Now let’s say we would like to create a few additional columns to document: 1) culmen to body mass index, 2) flipper group categories based on flipper length, and 3) body size category identifying if the penguins were small, medium, or large based on their weight. We can do all three of these things using the mutate() function.\n\n# create a culmen to body mass index\n# assign a flipper length category\n# create another group based on weight class, and let's make sure that we do not assign a class to missing data\ncleandat4 &lt;- cleandat3 %&gt;% \n  mutate(body_mass_kg = body_mass_g/1000,\n         culmen_bodymass_index = round(culmen_length_mm/body_mass_kg, 2),\n         flipper_group = if_else(flipper_length_mm &gt; 210, \"big flips\", \n                                 \"small flips\" ),\n         weight_class = case_when(is.na(body_mass_g) ~ \"unknown\", \n                                  body_mass_g &lt;= 3500 ~ \"small\", \n                                  body_mass_g &lt; 4300 ~ \"medium\", \n                                  TRUE ~ \"large\"))\n\nNote: The round() function may not work as you expect. See the help file for how it rounds off at 5. If you’d like a different approach, you can use the round_half_up() or round_to_fraction() functions in the janitor package."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#formatting-calendar-dates-and-times",
    "href": "scripts/BYOD1_workshop.html#formatting-calendar-dates-and-times",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.8 Formatting calendar dates and times",
    "text": "5.8 Formatting calendar dates and times\nThe package lubridate, which is part of the tidyverse collection of packages, contains many useful functions to format and manipulate date and time variables. Some functions (e.g., as.Date()) are part of base R, while others are part of the lubridate package.\n\n\n\nUseful functions to format dates and times\n\n\nFunction\nPurpose\n\n\n\n\nas.POSIXct()\nFormat date and time as POSIXct object\n\n\nas_date() or as.Date()\nFormat object as a date\n\n\nyear()\nExtract year from POSIXct object\n\n\nmonth()\nExtract month from POSIXct object\n\n\nhour()\nExtract hour from POSIXct object\n\n\n\n\n\nHere you can find a useful tutorial that explores and presents some of these functions.\nLet’s first add a “time” variable to our dataset. The time variable will be in total number of seconds from 00:00:00. We will learn how to re-format this in proper time stamp (hour:minute:second) so that it is more intuitive to work with and visualize. Times in seconds frequently happen with GPS Location data, for example. It isn’t a bad idea to have a way to convert them in your toolbox!\nThe code that we will type next is only used to generate a time variable. Don’t worry too much about the specifics of the code since this is not something that you would have to do if you were receiving data that already contains both a date and a time column. This is only done to illustrate how to work with both dates and times, since our original penguin data only contains dates.\n\n# define the start and end dates/times for the range of sampling times (in UTC, i.e., 3 hours ahead of the time zone where penguins were observed - see note below)\nstart_time &lt;- 9*60*60 # 9 am in seconds from midnight\nend_time &lt;- 21*60*60 # 9 pm in seconds from midnight\n\n# Create a sequence of all possible timestamps within the range, e.g., by 10 minute segments\nfull_time_sequence &lt;- seq(start_time, end_time, 10*60)\n\n# For each record, sample a random number from the full time sequence created above\ncleandat5 &lt;- cleandat4 %&gt;% \n  mutate(time_sec = sample(full_time_sequence, n(), replace=TRUE)) \n\n# check variable\ncleandat5$time_sec\n\nWe have now generated a new variable time_sec which reflects the time of day in seconds from the starting point 00:00:00. We will learn below how to re-format those times so that they are in the appropriate time zone.\nNote: Time zones are important in R!!! If not specified, the dates and times will be assigned the time zone of your computer system, which may be misleading if the data was collected somewhere completely different (e.g., penguins in Antarctica!).\nLet’s format our new time variable to make it more usable in analyses and visualizations.\n\n# check the timezone of your computer\nSys.time()\n\n# set date_egg as the date\n# create a date and time variable. Note that although the penguins are from the Palmer LTER in Antarctica, which is in UTC-03, data were collected in UTC times and will need to be converted to UTC-03.  \n# convert to proper time zone UTC-03 \ncleandat6 &lt;- cleandat5 %&gt;% \n  mutate(date = as_date(date_egg),\n         date_time_utc = as_date(date_egg, format = \"%Y-%m-%d\") %&gt;% \n           paste(\"00:00:00\") %&gt;% \n           as.POSIXct(format=\"%Y-%m-%d %H:%M:%S\", tz = \"UTC\") + time_sec,\n         date_time_utc03 = as.POSIXct(date_time_utc, tz = \"Etc/GMT+3\"))\n                                    \n\n# look at the first few entries\ncleandat6 %&gt;% \n  select(date, time_sec, date_time_utc, date_time_utc03) %&gt;% \n  head(n = 10)\n\nNote: From R help file on time zones : “Most platforms support time zones of the form ‘⁠Etc/GMT+n⁠’ and ‘⁠Etc/GMT-n⁠’ (possibly also without prefix ‘⁠Etc/⁠’), which assume a fixed offset from UTC (hence no DST). Contrary to some expectations (but consistent with names such as ‘⁠PST8PDT⁠’), negative offsets are times ahead of (East of) UTC, positive offsets are times behind (West of) UTC.”\nNow that we’ve formatted our date and time variable as POSIXct object with the appropriate time zone, we can extract all sorts of useful information very easily (e.g., hour(), month(), year()).\n\n# study year\nyear(cleandat6$date_time_utc03)\n\n# use the mutate function to create a year column in the cleandat dataframe\ncleandat7 &lt;- cleandat6 %&gt;% \n  mutate(year = year(date_time_utc03)) \n\nExercise: Take a few minutes to experiment extracting different types of information from the POSIXct object. Are there situations where you see this could be useful (e.g., hour())? What happens if you run as_date() on a date and time POSIXct object?"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#long-and-wide-data",
    "href": "scripts/BYOD1_workshop.html#long-and-wide-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.9 Long and wide data",
    "text": "5.9 Long and wide data\nOne of the principles of tidy data is for it to be “long” (i.e., each observation has a row). However, it may make sense to collect data in a “wide” format. There may also be calculations that are easier to do in a wide format. The “pivot_” functions allow us to move between long and wide formats.\n\n# make body mass wide by year\nwidedat &lt;- cleandat7 %&gt;% \n  select(individual_id, body_mass_kg, year) %&gt;% \n  pivot_wider(names_from = year,\n              values_from = body_mass_kg,\n              names_prefix = \"year_\")\n\n# look at new dataset\nwidedat\n\n# convert it back to long\nlongdat &lt;- widedat %&gt;% \n  pivot_longer(cols = starts_with(\"year_\"),\n               names_to = \"year\",\n               values_to = \"body_mass_kg\",\n               names_prefix = \"year_\")\n\n# look at new dataset\nlongdat"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#saving-data",
    "href": "scripts/BYOD1_workshop.html#saving-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.10 Saving data",
    "text": "5.10 Saving data\nNow that we’ve cleaned our data, let’s save it to our project. That way, if we want to put down our work and come back later, we can start with clean data and not re-do the steps. We can also give this dataset to collaborators.\n\n# write to a csv file\nwrite_csv(cleandat7, \"data/clean_penguindat.csv\")\n\nIf we want to import the data into a script, we can use the read_csv() function, as demonstrated above."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#key-data-visualization-principles",
    "href": "scripts/BYOD1_workshop.html#key-data-visualization-principles",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.1 Key data visualization principles",
    "text": "7.1 Key data visualization principles\nRougier et al. present ten simple rules for better figures in their 2014 paper:\n\nKnow your audience\nIdentify your message\nAdapt the figure to support the medium (e.g., presentation, report)\nCaptions are not optional\nDo not trust the defaults\nUse color effectively\nDo not mislead the reader/viewer\nAvoid “chartjunk”\nMessage &gt; beauty\nGet the right tool\n\nR can be the right tool for many data visualizations. Start by thinking about your audience, message, and medium. This can help you decide whether R is a good fit."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#main-elements-of-a-ggplot-figure",
    "href": "scripts/BYOD1_workshop.html#main-elements-of-a-ggplot-figure",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.2 Main elements of a ggplot figure",
    "text": "7.2 Main elements of a ggplot figure\nPlots in ggplot are built as a series of layers sequentially added in an intuitive way. Let’s think about how we would graph a figure by hand. First, we would think of the basic component of our figure or in other words the things that we want to represent (i.e., the data). We would then think of what specifically we want to represent (i.e., The Xs, the Ys, etc.), and how (i.e., the type of chart). ggplot uses this logic to sequentially add complexity and layers to plots with limitless options!\n\n\n\nElements of a plot done in ggplot\n\n\nElement\nDefinition\n\n\n\n\nBasics\nData to be mapped\n\n\nAesthetics\nAesthetics of the graph such as X and Y (if more then one variable), grouping variables, or colours or shape\n\n\nGeometry\nDefines the type of plot\n\n\nLabels and legends\nAxis and legend labels\n\n\nThemes\nDefine the appearance of the plot\n\n\nScales\nScales for the X and Y axis\n\n\nFaceting\nDivides the plot into subplots\n\n\nStatistics\nBuilds new variables (e.g., regression line) to plot\n\n\nCoordinate systems\nDefines the relationship between X and Y\n\n\n\n\n\nFor each of these elements, you can find a detailed description on the ggplot2 cheatsheet. We will give some examples of the types of figures that we can do in ggplot, and how to add layers and complexity without having to add so many lines of code that it becomes cumbersome! Let’s explore some of the syntax using examples for one variable and two variables."
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#one-variable-figures",
    "href": "scripts/BYOD1_workshop.html#one-variable-figures",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.3 One-variable figures",
    "text": "7.3 One-variable figures\nWe’ll start with our cleaned dataset, but let’s save it to a final name, cleandat. That way, if we change the cleaning steps above, we just need to update the number here without changing all of our code for figures.\n\n# save final dataset with consistent name\ncleandat &lt;- cleandat7\n\n# remind ourselves of the dataset\nglimpse(cleandat)\n\nWe may want to visualize the number of records that we have for each of the islands. Let’s first set up the basics, or canvas, for our plot and specify the data.\n\nggplot(data = cleandat)\n\n\n\n\n\n\n\n\nThis is pretty much a blank slate on which we can add aesthetics (fancy word to mean: what is it that we want to show on our figure?). Let’s first take a look at the list of possible aesthetics.\n\n\n\nOptions to be passed into the `aes` statement\n\n\nAesthetics\nDescription\n\n\n\n\nx\nVariable to be plotted on the X axis\n\n\ny\nVariable to be plotted on the Y axis\n\n\nsize\nSize of the point, column or line\n\n\nalpha\nTransparency of the object\n\n\nfill\nThe fill colour of a column area\n\n\ncolour\nThe colour for points and lines, or the outline colour for columns and areas\n\n\nshape\nThe shape of the point when making a scatter plot\n\n\n\n\n\nWe add different elements to the blank canvas using the plus sign. Let’s count how many records we have per island in our cleaned dataset. Island will thus be on the x-axis, which is our only variable in this plot.\n\nggplot(data = cleandat) + \n  aes(x = island)\n\n\n\n\n\n\n\n\nAdding aes(x = island) simply added the x-axis to our blank canvas. We can now fill it by specifying the type of plot that we want to make with this. For simply visualizing the number of records per island we can do a barchart, which we specify using one of the available geometries as noted on the ggplot2 cheatsheet.\n\nggplot(data = cleandat) + # blank canvas\n  aes(x = island) + # define the X-axis\n  geom_bar() # type of graph\n\n\n\n\n\n\n\n\nWe’re off to a great start! But this figure could show more information, such as the number of records for each species on each of these islands. Recall the description of the aesthetics options, one being fill which can indicate the fill color of the bar based on a categorical variable.\n\nggplot(data = cleandat) +\n  aes(x = island, fill = species) +\n  geom_bar()\n\n\n\n\n\n\n\n\nLet’s add labels and make the graph look a little bit nicer by removing the grey background color. Labels can be added using the labs() function, and the theme can be adjusted to change the overall appearance of the figure. Here, we use a black-and-white theme, but there are many available.\n\nggplot(data = cleandat) +\n  aes(x = island, fill= species) +\n  geom_bar() +\n  labs(title = \"Penguin species per island\",\n       x = \"Island\",\n       y = \"Number of penguins\",\n       fill = \"Species\") + # \"fill=\"Species\" will change the legend title for the fill aesthetics \n  theme_bw()\n\n\n\n\n\n\n\n\nThis figure is starting to look pretty good! You can spend time exploring different themes and taking a look at what the output looks like.\nAn additional thing that we can do is adjust the color. We can use the function scale_fill_brewer() to pick a different color scheme. The available color palettes can be viewed in RColorBrewer palette. This tool offers an opportunity to select only colors that are colorblind safe or printer friendly, among other things.\n\nggplot(data = cleandat) +\n  aes(x = island, fill= species) +\n  geom_bar() +\n  labs(title = \"Penguin species per island\",\n       x = \"Island\",\n       y = \"Number of penguins\",\n       fill = \"Species\") + \n  theme_bw() + \n  scale_fill_brewer(type = \"qual\", palette = 3)\n\n\n\n\n\n\n\n\nOften it is more desirable to look at bars that aren’t stacked but that are side-by-side. The position of the bars can be adjusted with the geom_bar() function. Let’s add this to our figure above since it looks so nice already!\n\nggplot(data = cleandat) +\n  aes(x = island, fill= species) +\n  geom_bar(position = position_dodge(preserve = \"single\")) +\n  labs(title = \"Penguin species per island\",\n       x = \"Island\",\n       y = \"Number of penguins\",\n       fill = \"Species\") + \n  theme_bw() + \n  scale_fill_brewer(type = \"qual\", palette = 3)\n\n\n\n\n\n\n\n\nExercise: Now it is your turn to play with single-variable plots! Refer to the ggplot2 cheatsheet and try making a histogram of the penguins body weights to see how the weights are distributed across the dataset overall. Then, add complexity to this figure by visualizing how the distribution of body weight varies across species! Hint: if the species-specific bars are overlapping, you can add transparency using the alpha aesthetic within the geometry function.\nAs you can see, the options are limitless!"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#two-variables-figures",
    "href": "scripts/BYOD1_workshop.html#two-variables-figures",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.4 Two-variables figures",
    "text": "7.4 Two-variables figures\nIn most instances we want to show relationships between two variables, sometimes we also want to show how that relationship varies across groups. We will demonstrate this with the penguin dataset by building a figure of the relationship between penguins flipper length and body mass.\nWe’ve already seen how to build a figure from the basic level (data only) to a nice figure with labels, titles, and better colors, so we can go ahead and build a nice scatterplot right away. The geometry to use in that instance will be geom_point() instead of geom_bar(). Here will have a X and a Y variable to pass to the aes() function.\n\nggplot(data = cleandat)+\n  aes(x = body_mass_g, y = flipper_length_mm) + \n  geom_point() +\n  labs(title = \"Relationship between flipper length and body mass\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAbove we see the relationship using the full dataset (i.e., all species across all islands). We could follow a similar approach as above to show how that relationship varies across species. We could use different colors and/or different shapes to highly species-specific patterns. Let’s experiment with this and use the same colour palette as above!\n\nggplot(data = cleandat)+\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) + \n  geom_point() +\n  labs(title = \"Relationship between flipper length and body mass\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") +\n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3)\n\n\n\n\n\n\n\n\nInteresting! Intuitively our eyes are trying to draw regression lines through the cloud of points. It is possible to add these lines on the figure using the geom_smooth() function.\n\nggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) + \n  geom_point() +\n  labs(title = \"Relationship between flipper length and body mass\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") +\n  theme_bw() +\n  scale_colour_brewer(type =\"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x') \n\n\n\n\n\n\n\n\nNote: se = TRUE would show confidence limits based on the standard error. The color follows the same as the cloud of points because it’s in the initial aes and does not need to be added again here. If you specify the color within geom_point() or geom_smooth() using aes(), it will only apply to that layer.\nIf you would like you can take a moment to play with other variables and make additional figures. Also note that this is a pretty clean dataset and straight regression lines seem to fit pretty well. This isn’t always the case, however, and the figures do not replace thorough statistical tests and models!\nExercise: Repeat the same figure as above but show species as different colors and islands as different shapes. What do you notice?"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#facets",
    "href": "scripts/BYOD1_workshop.html#facets",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.5 Facets!",
    "text": "7.5 Facets!\nAt times we may want to display complex information for several categories simultaneously, and adding all of that complexity to one graph leads to figures that can be difficult to interpret. Using facets we can display the same figure in different panels based on the values of a categorical variable. For example, instead of using different shapes for the different islands, we could use facet_wrap() function as below.\n\nggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) +   \n  geom_point() +\n  labs(title=\"Island comparision of flipper length and body mass by species\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") + \n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x') +\n  facet_wrap(~island)\n\n\n\n\n\n\n\n\nExercise: Try adding scales=\"free\" argument within facet_wrap() and see what happens. Would this be a useful figure if the purpose was to compare the different islands? Are there cases where it would be useful?"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#interactive-plots",
    "href": "scripts/BYOD1_workshop.html#interactive-plots",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.6 Interactive plots",
    "text": "7.6 Interactive plots\nThe plotly package provides functionality for making interactive plots that has tools for zooming in and out, panning, hovering and among others. While this package has many different ways to create these plots with different level of functionality, the simplest is the ggplotly() function which adds these tools to ggplots. This can be very useful for exploring data.\n\n# install and load the plotly package\n# install.package(\"plotly\") # delete the '#' to install\nlibrary(plotly)\n\nThere are two ways to run the ggplotly() function. First, simply wrap the ggplotly() function around the chain of functions used to make a ggplot.\n\nggplotly(\n  ggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) +   \n  geom_point() +\n  labs(title=\"Island comparision of flipper length and body mass by species\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") + \n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x')\n)\n\n\n\n\n\nThe other is to name the chain of functions and wrap that named object in the ggplotly() function\n\nfliplen_bodmass_plot &lt;-  ggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) +   \n  geom_point() +\n  labs(title=\"Island comparision of flipper length and body mass by species\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") + \n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x')\n\nggplotly(fliplen_bodmass_plot)"
  },
  {
    "objectID": "scripts/BYOD1_workshop.html#exporting-plots-for-publication",
    "href": "scripts/BYOD1_workshop.html#exporting-plots-for-publication",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.7 Exporting plots for publication",
    "text": "7.7 Exporting plots for publication\nOne of the easiest way to save and export plots is to use the ggsave() function. Use the ?ggsave to obtain more information on how the function works. By default, the latest plot displayed will be saved, but if a previously displayed plot had been saved as an R object, the name of that R object can be specified to save that one instead of the last one. Options available here include dpi=..., width=... and height=... for our figure. This is where we can make the final adjustments depending if the plot is to be used in a powerpoint presentation, or a word document, for example.\nLet’s save one figure, and then play with these format options to see how it changes the appearance and quality of the exported image. Often it is by trial and errors that you will find the best format for your specific situation!\n\nggsave(\"outputs/penguins_data_exploration.jpg\",\n       plot = fliplen_bodmass_plot,\n       dpi = 300, height = 5, width = 7, units = \"in\")"
  },
  {
    "objectID": "index.html#packages",
    "href": "index.html#packages",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "3.1 Packages",
    "text": "3.1 Packages\nIn this section, we will learn about the different packages that we will be using in this workshop and will explore different functions for reading files into r.\n\n\n\nEssential R packages for tidying and visualizing data\n\n\nPackage\nPurpose\n\n\n\n\nreadr\nRead delimited files\n\n\nreadxl\nRead excel files\n\n\ntidyr\nTidy messy data\n\n\ndplyr\nFormat and summarize data tables\n\n\nstringr\nFormat character strings\n\n\njanitor\nMore data cleaning (not in the tidyverse)\n\n\nggplot2\nCreate elegant data visualisations using the grammar of graphics\n\n\ntidyverse\nLoad many of the packages in the tidyverse\n\n\n\n\n\nLet’s load packages!\n\n# load packages in the tidyverse (e.g., readr, readxl, tidyr)\nlibrary(tidyverse) \nlibrary(readxl)\n\n# we can check what packages were loaded\nnames(sessionInfo()[[\"otherPkgs\"]])"
  },
  {
    "objectID": "index.html#loading-data",
    "href": "index.html#loading-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "3.2 Loading data",
    "text": "3.2 Loading data\nLet’s load a few datasets in different formats. First, you’ll need to download the data to your computer and save it in a folder called “data” that’s inside of your RStudio project.\npenguin_data_final.xlsx\nSince we stored the data inside a folder in the project, the file path is very simple. If you need to load data that is stored outside the project, you will need to specify the whole file path.\n\n# load a .xlsx file into your R environment\nmydat_xls &lt;- read_excel(\"data/penguin_data_final.xlsx\") \n\nNext, let’s try loading data from a url. We would use the read_csv function for data on our computer as well.\n\n# load a .csv file into your R environment\nmydat_csv &lt;- read_csv(\"https://raw.githubusercontent.com/MN-DNR-R/BYOD_Seminar1_Data_Summaries_and_Visualization/refs/heads/main/data/penguin_data_final.csv\") \n\nA summary of the data is generated when you use the “read_” functions. You can also look in the environment and make sure that the files were loaded properly! We will also demonstrate ways to explore your data in the next section."
  },
  {
    "objectID": "index.html#data-from-a-package",
    "href": "index.html#data-from-a-package",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "3.3 Data from a package",
    "text": "3.3 Data from a package\nSome datasets are stored inside of R packages. We will use one that’s in a package for the rest of our demonstration.\nThe palmerpenguins package was created by Allison Horst, Alison Hill, and Kristen Gorman as a tool for teaching data manipulation and analysis techniques in R. In the following sections we will explore the data available within this package, and we will learn to manipulate and visualize the data using a variety of tools and techniques. Below you will use the citation() command line to get the full citation for the package!\nThe library contains two datasets which can be called without having to read them manually (as we previously did with the .csv or .xlsx files). One which contains raw penguins data (penguin_raw), and the second file (penguins) is the simplified (i.e., clean) dataset.\nYou also can read more about the package here: PalmerPenguins\n\n# install package (delete the '#' to run the line and use the '#' after you've installed the package)\n# install.packages(\"palmerpenguins\")\n\n# load library into your R environment \nlibrary(palmerpenguins)\n\n# get information about the package:\n?palmerpenguins\n\n# Get proper citation for the package (e.g., to use in a publication). Note that you can use the \"citation\" function for any of the packages used in an analysis, which is very useful when writing the methods in a report or peer-reviewed manuscript. \ncitation(\"palmerpenguins\")\n\n# let's save the raw data in our environment\nrawdat &lt;- penguins_raw"
  },
  {
    "objectID": "index.html#data-exploration-functions",
    "href": "index.html#data-exploration-functions",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.1 Data exploration functions",
    "text": "4.1 Data exploration functions\nThere are many functions available to explore the data. Here is a list of the main ones that we will be using in this workshop.\n\n\n\nUseful functions for data exploration\n\n\nFunction\nPurpose\n\n\n\n\nglimpse()\nOverview of dataframe rows, columns, column names, dataframe dimension, and a glimpse of first values\n\n\nstr()\nSuccinct summary of all columns of a dataframe; similar to glimpse but within base R\n\n\nnames()\nColumn names\n\n\nhead()\nDisplay first n rows of data (default is 6)\n\n\ntail()\nDisplays last n rows of data (default is 6)\n\n\nnrow()\nNumber of rows\n\n\nncol()\nNumber of columns\n\n\nsummary()\nSummary of the data in each column\n\n\nunique()\nDisplays unique values of a variable"
  },
  {
    "objectID": "index.html#data-types",
    "href": "index.html#data-types",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.2 Data types",
    "text": "4.2 Data types\nBefore doing any data manipulation in R, it is important to recognize the different data types. When importing your data into R, R will automatically recognize the type of data of each column. At times, however, a specific data type may need to be set or converted from one to another.\nFor example, one could use the as.numeric() function to convert a column to numeric, or as.character() to convert to character. When doing such data conversions, it is important to note that some elements of a vector may be converted to NAs if R recognizes that it does not correspond to the data type specified.\nA good example of this is when a column that should be numeric contains characters (e.g., instead of an actual count one had recorded something like “more then 100 animals”). In this case, this would return an “NA” as R does not know what to do with this information! Good data entry and quality checks prior to importing data into R are very important to help prevent data loss.\nWith a factor data type, you can specify the order of variables, such as “low”, “medium”, “high”. This defined order can then make data visualizations and analyses more intuitive.\n\n\n\nData types supported in R\n\n\nType\nExample\n\n\n\n\nNumeric\n1.5, 2.6\n\n\nInteger\n1, 2\n\n\nLogical\nTrue/False\n\n\nCharacter\nOne, Two\n\n\nFactor\nControl, Treatment"
  },
  {
    "objectID": "index.html#examining-the-data",
    "href": "index.html#examining-the-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.3 Examining the data",
    "text": "4.3 Examining the data\nLet’s use the functions from the function description table above to examine what is contained in our dataset.\n\n# the glimpse function provides a good first overview of the data\nglimpse(rawdat)\n\n# the str function also provides a quick but complete overview of the structure of the data\nstr(rawdat)\n\n# quick summary of all of the data\nsummary(rawdat)\n\n# print column names\nnames(rawdat)\n\n# look at first and last rows\nhead(rawdat, n = 10)\ntail(rawdat, n = 10)\n\n# number of rows and columns\nnrow(rawdat)\nncol(rawdat)\n\n# lists unique values (this can help identify if there are data entry errors)\nunique(rawdat$Species)\nunique(rawdat$Island)\nunique(rawdat$Region)\n\n# How many unique ID's do we have? How many data points do we have? Do they match?\nunique(rawdat$`Individual ID`)"
  },
  {
    "objectID": "index.html#data-quality-check",
    "href": "index.html#data-quality-check",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "4.4 Data quality check",
    "text": "4.4 Data quality check\nLooking at the raw data, what could be improved for analyses and data visualizations? Is the dataset pretty clean and analysis-ready, or are these things that need to be addressed and changed so that we don’t run into issues later in the process?\nHere are some examples:\n\nnames in the Species column are long\nthe Sex and Stage columns are characters, but they would be more useful as factors\n\nExercise: Can you think of any others?"
  },
  {
    "objectID": "index.html#what-is-tidy-data",
    "href": "index.html#what-is-tidy-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.1 What is tidy data?",
    "text": "5.1 What is tidy data?\nWe refer to “tidy data” as a dataset where each column is a variable, each row is an observation, and each cell contains a single value and a data type that is consistent across a given column (e.g., all numeric). The tidyverse packages contains functions for manipulating the data so that we can create a clean, tidy dataset to be used for all analyses.\nNote: Recall that we will never overwrite the original dataset. The raw data should always remain in its original location and be unaltered. The beauty of R scripts is that we can save all data cleaning and data manipulation steps while retaining the original data\nWhy is it important to tidy our data?\nTaking time to tidy a dataset ensures that the data summaries, analyses, or visualizations we produce represent “true” data values to the best of our knowledge (e.g., no wrongly assigned values, missing data, or data entry errors). It is a the first and most critical step of any data analysis, and though it can be a lengthy process, it is worth the effort.\nWhy tidy data in R?\nUsing R ensures that the original dataset is kept unaltered, and that all data manipulation steps are documented and reproducible. This is a major advantage of tidying data in R as opposed to using spreadsheet applications such as Excel, where there is often few to no records of changes made to a dataset."
  },
  {
    "objectID": "index.html#the-pipe-operator",
    "href": "index.html#the-pipe-operator",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.2 The pipe operator",
    "text": "5.2 The pipe operator\nR uses many different operators such as &lt;- and = along with typical arithmetic (+, -, *, /, ^) and relational (&lt;, &gt;, &lt;=, &gt;=, == ,!=) symbols. The pipe operator (%&gt;% or |&gt;) provides a way to efficiently chain functions together in a single statement. It is similar to saying: let’s take this data, and then do this with it, and then do this, kind of like a data assembly line! So ultimately, every time that you see or use %&gt;% or |&gt; in a script, you can think of it as being the same as if you were reading or coding and then…! It is a very useful tool for tidying data.\nThe operator |&gt; is from base R while %&gt;% is from the tidyverse package magrittr. More background on the origin and use of the pipe operator can be found here.\nLet’s look at an example of tidying data with and without the pipe operator.\n\n# edit the raw data to filter for samples collected from Torgersen Island and arrange the table by the date the egg was collected\n\n# without the pipe operator\ntorg1 &lt;- filter(rawdat, Island == \"Torgersen\")\ntorg2 &lt;- arrange(torg1, 'Date Egg')\n\n# with the pipe operator\ntorg &lt;- rawdat %&gt;% \n  filter(Island == \"Torgersen\") %&gt;% \n  arrange('Date Egg')\n\nWhen using the pipe operator, the input from before the pipe becomes the first argument in the function after the pipe. If you want the input to be the second, third, etc. argument, represent its location with .."
  },
  {
    "objectID": "index.html#tidy-functions",
    "href": "index.html#tidy-functions",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.3 Tidy functions",
    "text": "5.3 Tidy functions\nNow that we’ve introduced a few basic tidy data concepts and tools, we can start tidying our data. There are many very useful functions to subset data, re-arrange columns, create new columns, etc. Below are the ones you may use more frequently as you learn to tidy your data in R and with the tidyverse packages.\n\n\n\nUseful functions to create tidy data\n\n\nFunction\nPurpose\n\n\n\n\nfilter()\nKeep (or exclude) rows that meet specific criteria\n\n\nselect()\nSelect columns to keep (or to drop)\n\n\narrange()\nSort a dataframe based on a column's value (or several columns' values)\n\n\nmutate()\nAdd new columns or update existing columns\n\n\nrename()\nRename columns"
  },
  {
    "objectID": "index.html#formating-column-names",
    "href": "index.html#formating-column-names",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.4 Formating column names",
    "text": "5.4 Formating column names\nSome of the column names are difficult to work with because they have spaces and symbols. Let’s fix that.\n\n# look at the column names\nhead(rawdat)\nnames(rawdat)\n\n# let's make the following changes:\n# lowercase names\n# replace spaces with _\n# replace / with _\n# remove parentheses\nrawdat2 &lt;- rawdat %&gt;% \n  rename_with(.fn = str_to_lower) %&gt;% \n  rename_with(.fn = ~str_replace_all(.x, \" \", \"_\")) %&gt;% \n  rename_with(.fn = ~str_replace_all(.x, \"/\", \"_\")) %&gt;% \n  rename_with(.fn = ~str_remove_all(.x, \"\\\\(|\\\\)\"))\n\n# look at new names\nnames(rawdat2)\n\nThe functions str_to_lower() and str_replace_all() are part of the stringr package, automatically loaded when we load tidyverse, but it could be loaded individually as well. The function rename_with() is like rename(), but allows you to use functions within it. Use rename() if you want to do a one-to-one change in column names."
  },
  {
    "objectID": "index.html#removing-unecessary-data",
    "href": "index.html#removing-unecessary-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.5 Removing unecessary data",
    "text": "5.5 Removing unecessary data\nTo simplify the dataset, let’s remove columns and rows we don’t need. We will now rename the dataset as “cleandat” so that we maintain the raw data unaltered, and save all changes and additions into the clean dataset. The columns we select will correspond to the analyses we’re interested in. If data are missing, we may want to remove those observations from the dataset.\n\n# let's see whether all the observations have flipper length\nrawdat2 %&gt;% \n  filter(is.na(flipper_length_mm))\n\n# keep only columns of interest\n# use select to remove columns (an alternative approach)\n# remove observations (rows) missing flipper length\ncleandat1 &lt;- rawdat2 %&gt;% \n  select(individual_id, species, region, island, stage, clutch_completion, \n         date_egg, flipper_length_mm, culmen_length_mm, body_mass_g,sex, \n         comments) %&gt;% \n  select(!stage & !region) %&gt;% \n  filter(!is.na(flipper_length_mm))"
  },
  {
    "objectID": "index.html#modifying-variables",
    "href": "index.html#modifying-variables",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.6 Modifying variables",
    "text": "5.6 Modifying variables\nOften, variables that are characters need to be formatted to make them easier to use for analyses. We’ll rename the dataset again to keep the original data saved.\n\n# look at species names\nunique(cleandat1$species)\n\n# remove the scientific name\ncleandat2 &lt;- cleandat1 %&gt;% \n  mutate(species = str_remove(species, \" \\\\(Pygoscelis adeliae\\\\)\") %&gt;% \n           str_remove(\" \\\\(Pygoscelis papua\\\\)\") %&gt;% \n           str_remove(\" \\\\(Pygoscelis antarctica\\\\)\"))\n\n# look at new species names\nunique(cleandat2$species)\n\n\n5.6.1 Flagging usability of data\nIf it looks like some records may not be usable based on some criteria, it may be a good idea to create an indicator variable (yes/no) that identifies which record may not be usable for a specific analysis. If needed, we can do this using the mutate and case_when functions.\n\n# look at the comments to assess if some data may not be usable for analysis  \nunique(cleandat2$comments)\n\n# create an indicator variable for whether the sex variable is usable\ncleandat3 &lt;- cleandat2 %&gt;% \n  mutate(usable_sex_data = case_when(\n    str_detect(comments, \"No blood sample obtained\") ~ \"no\",\n    str_detect(comments, \"Sexing primers did not amplify\") ~ \"no\",\n    TRUE ~ \"yes\"))\n\n# let's see if this flag works\ncleandat3 %&gt;% \n  distinct(usable_sex_data, sex)\n\nNote: While in this example the number of unique comments to look through was relatively small and we could easily decide which ones to use for coding the “usable” columns as “yes” or “no”, in real life it is very impractical and not advised to store any critical information in a general free-form “comments” column, especially if that information pertains to the quality or usability of the data. The best practice is to maintain a metadata spreadsheet that contains all of the sampling information for a given sampling point, including comments, but that would also contain a column with a “yes” or a “no” value so that the analyst can quickly filter data without having to weed through long comments or make decisions on what they may mean. Just something to keep in mind!\n\nAt times, though, we can create a is-the-data-usable (Yes/No) column based on some variables (but not free-form comments!). For example, if one had sample-site specific wind, precipitation, temperature, time of day information, it would be easy to generate a “data quality” variable based on specific sampling conditions (e.g., if wind exceeds this, exclude this data point)."
  },
  {
    "objectID": "index.html#creating-new-variables",
    "href": "index.html#creating-new-variables",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.7 Creating new variables",
    "text": "5.7 Creating new variables\nWe’re getting close to having a dataset that will be easier to use for analysis! Now let’s say we would like to create a few additional columns to document: 1) culmen to body mass index, 2) flipper group categories based on flipper length, and 3) body size category identifying if the penguins were small, medium, or large based on their weight. We can do all three of these things using the mutate() function.\n\n# create a culmen to body mass index\n# assign a flipper length category\n# create another group based on weight class, and let's make sure that we do not assign a class to missing data\ncleandat4 &lt;- cleandat3 %&gt;% \n  mutate(body_mass_kg = body_mass_g/1000,\n         culmen_bodymass_index = round(culmen_length_mm/body_mass_kg, 2),\n         flipper_group = if_else(flipper_length_mm &gt; 210, \"big flips\", \n                                 \"small flips\" ),\n         weight_class = case_when(is.na(body_mass_g) ~ \"unknown\", \n                                  body_mass_g &lt;= 3500 ~ \"small\", \n                                  body_mass_g &lt; 4300 ~ \"medium\", \n                                  TRUE ~ \"large\"))\n\nNote: The round() function may not work as you expect. See the help file for how it rounds off at 5. If you’d like a different approach, you can use the round_half_up() or round_to_fraction() functions in the janitor package."
  },
  {
    "objectID": "index.html#formatting-calendar-dates-and-times",
    "href": "index.html#formatting-calendar-dates-and-times",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.8 Formatting calendar dates and times",
    "text": "5.8 Formatting calendar dates and times\nThe package lubridate, which is part of the tidyverse collection of packages, contains many useful functions to format and manipulate date and time variables. Some functions (e.g., as.Date()) are part of base R, while others are part of the lubridate package.\n\n\n\nUseful functions to format dates and times\n\n\nFunction\nPurpose\n\n\n\n\nas.POSIXct()\nFormat date and time as POSIXct object\n\n\nas_date() or as.Date()\nFormat object as a date\n\n\nyear()\nExtract year from POSIXct object\n\n\nmonth()\nExtract month from POSIXct object\n\n\nhour()\nExtract hour from POSIXct object\n\n\n\n\n\nHere you can find a useful tutorial that explores and presents some of these functions.\nLet’s first add a “time” variable to our dataset. The time variable will be in total number of seconds from 00:00:00. We will learn how to re-format this in proper time stamp (hour:minute:second) so that it is more intuitive to work with and visualize. Times in seconds frequently happen with GPS Location data, for example. It isn’t a bad idea to have a way to convert them in your toolbox!\nThe code that we will type next is only used to generate a time variable. Don’t worry too much about the specifics of the code since this is not something that you would have to do if you were receiving data that already contains both a date and a time column. This is only done to illustrate how to work with both dates and times, since our original penguin data only contains dates.\n\n# define the start and end dates/times for the range of sampling times (in UTC, i.e., 3 hours ahead of the time zone where penguins were observed - see note below)\nstart_time &lt;- 9*60*60 # 9 am in seconds from midnight\nend_time &lt;- 21*60*60 # 9 pm in seconds from midnight\n\n# Create a sequence of all possible timestamps within the range, e.g., by 10 minute segments\nfull_time_sequence &lt;- seq(start_time, end_time, 10*60)\n\n# For each record, sample a random number from the full time sequence created above\ncleandat5 &lt;- cleandat4 %&gt;% \n  mutate(time_sec = sample(full_time_sequence, n(), replace=TRUE)) \n\n# check variable\ncleandat5$time_sec\n\nWe have now generated a new variable time_sec which reflects the time of day in seconds from the starting point 00:00:00. We will learn below how to re-format those times so that they are in the appropriate time zone.\nNote: Time zones are important in R!!! If not specified, the dates and times will be assigned the time zone of your computer system, which may be misleading if the data was collected somewhere completely different (e.g., penguins in Antarctica!).\nLet’s format our new time variable to make it more usable in analyses and visualizations.\n\n# check the timezone of your computer\nSys.time()\n\n# set date_egg as the date\n# create a date and time variable. Note that although the penguins are from the Palmer LTER in Antarctica, which is in UTC-03, data were collected in UTC times and will need to be converted to UTC-03.  \n# convert to proper time zone UTC-03 \ncleandat6 &lt;- cleandat5 %&gt;% \n  mutate(date = as_date(date_egg),\n         date_time_utc = as_date(date_egg, format = \"%Y-%m-%d\") %&gt;% \n           paste(\"00:00:00\") %&gt;% \n           as.POSIXct(format=\"%Y-%m-%d %H:%M:%S\", tz = \"UTC\") + time_sec,\n         date_time_utc03 = as.POSIXct(date_time_utc, tz = \"Etc/GMT+3\"))\n                                    \n\n# look at the first few entries\ncleandat6 %&gt;% \n  select(date, time_sec, date_time_utc, date_time_utc03) %&gt;% \n  head(n = 10)\n\nNote: From R help file on time zones : “Most platforms support time zones of the form ‘⁠Etc/GMT+n⁠’ and ‘⁠Etc/GMT-n⁠’ (possibly also without prefix ‘⁠Etc/⁠’), which assume a fixed offset from UTC (hence no DST). Contrary to some expectations (but consistent with names such as ‘⁠PST8PDT⁠’), negative offsets are times ahead of (East of) UTC, positive offsets are times behind (West of) UTC.”\nNow that we’ve formatted our date and time variable as POSIXct object with the appropriate time zone, we can extract all sorts of useful information very easily (e.g., hour(), month(), year()).\n\n# study year\nyear(cleandat6$date_time_utc03)\n\n# use the mutate function to create a year column in the cleandat dataframe\ncleandat7 &lt;- cleandat6 %&gt;% \n  mutate(year = year(date_time_utc03)) \n\nExercise: Take a few minutes to experiment extracting different types of information from the POSIXct object. Are there situations where you see this could be useful (e.g., hour())? What happens if you run as_date() on a date and time POSIXct object?"
  },
  {
    "objectID": "index.html#long-and-wide-data",
    "href": "index.html#long-and-wide-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.9 Long and wide data",
    "text": "5.9 Long and wide data\nOne of the principles of tidy data is for it to be “long” (i.e., each observation has a row). However, it may make sense to collect data in a “wide” format. There may also be calculations that are easier to do in a wide format. The “pivot_” functions allow us to move between long and wide formats.\n\n# make body mass wide by year\nwidedat &lt;- cleandat7 %&gt;% \n  select(individual_id, body_mass_kg, year) %&gt;% \n  pivot_wider(names_from = year,\n              values_from = body_mass_kg,\n              names_prefix = \"year_\")\n\n# look at new dataset\nwidedat\n\n# convert it back to long\nlongdat &lt;- widedat %&gt;% \n  pivot_longer(cols = starts_with(\"year_\"),\n               names_to = \"year\",\n               values_to = \"body_mass_kg\",\n               names_prefix = \"year_\")\n\n# look at new dataset\nlongdat"
  },
  {
    "objectID": "index.html#saving-data",
    "href": "index.html#saving-data",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "5.10 Saving data",
    "text": "5.10 Saving data\nNow that we’ve cleaned our data, let’s save it to our project. That way, if we want to put down our work and come back later, we can start with clean data and not re-do the steps. We can also give this dataset to collaborators.\n\n# write to a csv file\nwrite_csv(cleandat7, \"data/clean_penguindat.csv\")\n\nIf we want to import the data into a script, we can use the read_csv() function, as demonstrated above."
  },
  {
    "objectID": "index.html#key-data-visualization-principles",
    "href": "index.html#key-data-visualization-principles",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.1 Key data visualization principles",
    "text": "7.1 Key data visualization principles\nRougier et al. present ten simple rules for better figures in their 2014 paper:\n\nKnow your audience\nIdentify your message\nAdapt the figure to support the medium (e.g., presentation, report)\nCaptions are not optional\nDo not trust the defaults\nUse color effectively\nDo not mislead the reader/viewer\nAvoid “chartjunk”\nMessage &gt; beauty\nGet the right tool\n\nR can be the right tool for many data visualizations. Start by thinking about your audience, message, and medium. This can help you decide whether R is a good fit."
  },
  {
    "objectID": "index.html#main-elements-of-a-ggplot-figure",
    "href": "index.html#main-elements-of-a-ggplot-figure",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.2 Main elements of a ggplot figure",
    "text": "7.2 Main elements of a ggplot figure\nPlots in ggplot are built as a series of layers sequentially added in an intuitive way. Let’s think about how we would graph a figure by hand. First, we would think of the basic component of our figure or in other words the things that we want to represent (i.e., the data). We would then think of what specifically we want to represent (i.e., The Xs, the Ys, etc.), and how (i.e., the type of chart). ggplot uses this logic to sequentially add complexity and layers to plots with limitless options!\n\n\n\nElements of a plot done in ggplot\n\n\nElement\nDefinition\n\n\n\n\nBasics\nData to be mapped\n\n\nAesthetics\nAesthetics of the graph such as X and Y (if more then one variable), grouping variables, or colours or shape\n\n\nGeometry\nDefines the type of plot\n\n\nLabels and legends\nAxis and legend labels\n\n\nThemes\nDefine the appearance of the plot\n\n\nScales\nScales for the X and Y axis\n\n\nFaceting\nDivides the plot into subplots\n\n\nStatistics\nBuilds new variables (e.g., regression line) to plot\n\n\nCoordinate systems\nDefines the relationship between X and Y\n\n\n\n\n\nFor each of these elements, you can find a detailed description on the ggplot2 cheatsheet. We will give some examples of the types of figures that we can do in ggplot, and how to add layers and complexity without having to add so many lines of code that it becomes cumbersome! Let’s explore some of the syntax using examples for one variable and two variables."
  },
  {
    "objectID": "index.html#one-variable-figures",
    "href": "index.html#one-variable-figures",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.3 One-variable figures",
    "text": "7.3 One-variable figures\nWe’ll start with our cleaned dataset, but let’s save it to a final name, cleandat. That way, if we change the cleaning steps above, we just need to update the number here without changing all of our code for figures.\n\n# save final dataset with consistent name\ncleandat &lt;- cleandat7\n\n# remind ourselves of the dataset\nglimpse(cleandat)\n\nWe may want to visualize the number of records that we have for each of the islands. Let’s first set up the basics, or canvas, for our plot and specify the data.\n\nggplot(data = cleandat)\n\n\n\n\n\n\n\n\nThis is pretty much a blank slate on which we can add aesthetics (fancy word to mean: what is it that we want to show on our figure?). Let’s first take a look at the list of possible aesthetics.\n\n\n\nOptions to be passed into the `aes` statement\n\n\nAesthetics\nDescription\n\n\n\n\nx\nVariable to be plotted on the X axis\n\n\ny\nVariable to be plotted on the Y axis\n\n\nsize\nSize of the point, column or line\n\n\nalpha\nTransparency of the object\n\n\nfill\nThe fill colour of a column area\n\n\ncolour\nThe colour for points and lines, or the outline colour for columns and areas\n\n\nshape\nThe shape of the point when making a scatter plot\n\n\n\n\n\nWe add different elements to the blank canvas using the plus sign. Let’s count how many records we have per island in our cleaned dataset. Island will thus be on the x-axis, which is our only variable in this plot.\n\nggplot(data = cleandat) + \n  aes(x = island)\n\n\n\n\n\n\n\n\nAdding aes(x = island) simply added the x-axis to our blank canvas. We can now fill it by specifying the type of plot that we want to make with this. For simply visualizing the number of records per island we can do a barchart, which we specify using one of the available geometries as noted on the ggplot2 cheatsheet.\n\nggplot(data = cleandat) + # blank canvas\n  aes(x = island) + # define the X-axis\n  geom_bar() # type of graph\n\n\n\n\n\n\n\n\nWe’re off to a great start! But this figure could show more information, such as the number of records for each species on each of these islands. Recall the description of the aesthetics options, one being fill which can indicate the fill color of the bar based on a categorical variable.\n\nggplot(data = cleandat) +\n  aes(x = island, fill = species) +\n  geom_bar()\n\n\n\n\n\n\n\n\nLet’s add labels and make the graph look a little bit nicer by removing the grey background color. Labels can be added using the labs() function, and the theme can be adjusted to change the overall appearance of the figure. Here, we use a black-and-white theme, but there are many available.\n\nggplot(data = cleandat) +\n  aes(x = island, fill= species) +\n  geom_bar() +\n  labs(title = \"Penguin species per island\",\n       x = \"Island\",\n       y = \"Number of penguins\",\n       fill = \"Species\") + # \"fill=\"Species\" will change the legend title for the fill aesthetics \n  theme_bw()\n\n\n\n\n\n\n\n\nThis figure is starting to look pretty good! You can spend time exploring different themes and taking a look at what the output looks like.\nAn additional thing that we can do is adjust the color. We can use the function scale_fill_brewer() to pick a different color scheme. The available color palettes can be viewed in RColorBrewer palette. This tool offers an opportunity to select only colors that are colorblind safe or printer friendly, among other things.\n\nggplot(data = cleandat) +\n  aes(x = island, fill= species) +\n  geom_bar() +\n  labs(title = \"Penguin species per island\",\n       x = \"Island\",\n       y = \"Number of penguins\",\n       fill = \"Species\") + \n  theme_bw() + \n  scale_fill_brewer(type = \"qual\", palette = 3)\n\n\n\n\n\n\n\n\nOften it is more desirable to look at bars that aren’t stacked but that are side-by-side. The position of the bars can be adjusted with the geom_bar() function. Let’s add this to our figure above since it looks so nice already!\n\nggplot(data = cleandat) +\n  aes(x = island, fill= species) +\n  geom_bar(position = position_dodge(preserve = \"single\")) +\n  labs(title = \"Penguin species per island\",\n       x = \"Island\",\n       y = \"Number of penguins\",\n       fill = \"Species\") + \n  theme_bw() + \n  scale_fill_brewer(type = \"qual\", palette = 3)\n\n\n\n\n\n\n\n\nExercise: Now it is your turn to play with single-variable plots! Refer to the ggplot2 cheatsheet and try making a histogram of the penguins body weights to see how the weights are distributed across the dataset overall. Then, add complexity to this figure by visualizing how the distribution of body weight varies across species! Hint: if the species-specific bars are overlapping, you can add transparency using the alpha aesthetic within the geometry function.\nAs you can see, the options are limitless!"
  },
  {
    "objectID": "index.html#two-variables-figures",
    "href": "index.html#two-variables-figures",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.4 Two-variables figures",
    "text": "7.4 Two-variables figures\nIn most instances we want to show relationships between two variables, sometimes we also want to show how that relationship varies across groups. We will demonstrate this with the penguin dataset by building a figure of the relationship between penguins flipper length and body mass.\nWe’ve already seen how to build a figure from the basic level (data only) to a nice figure with labels, titles, and better colors, so we can go ahead and build a nice scatterplot right away. The geometry to use in that instance will be geom_point() instead of geom_bar(). Here will have a X and a Y variable to pass to the aes() function.\n\nggplot(data = cleandat)+\n  aes(x = body_mass_g, y = flipper_length_mm) + \n  geom_point() +\n  labs(title = \"Relationship between flipper length and body mass\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAbove we see the relationship using the full dataset (i.e., all species across all islands). We could follow a similar approach as above to show how that relationship varies across species. We could use different colors and/or different shapes to highly species-specific patterns. Let’s experiment with this and use the same colour palette as above!\n\nggplot(data = cleandat)+\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) + \n  geom_point() +\n  labs(title = \"Relationship between flipper length and body mass\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") +\n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3)\n\n\n\n\n\n\n\n\nInteresting! Intuitively our eyes are trying to draw regression lines through the cloud of points. It is possible to add these lines on the figure using the geom_smooth() function.\n\nggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) + \n  geom_point() +\n  labs(title = \"Relationship between flipper length and body mass\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") +\n  theme_bw() +\n  scale_colour_brewer(type =\"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x') \n\n\n\n\n\n\n\n\nNote: se = TRUE would show confidence limits based on the standard error. The color follows the same as the cloud of points because it’s in the initial aes and does not need to be added again here. If you specify the color within geom_point() or geom_smooth() using aes(), it will only apply to that layer.\nIf you would like you can take a moment to play with other variables and make additional figures. Also note that this is a pretty clean dataset and straight regression lines seem to fit pretty well. This isn’t always the case, however, and the figures do not replace thorough statistical tests and models!\nExercise: Repeat the same figure as above but show species as different colors and islands as different shapes. What do you notice?"
  },
  {
    "objectID": "index.html#facets",
    "href": "index.html#facets",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.5 Facets!",
    "text": "7.5 Facets!\nAt times we may want to display complex information for several categories simultaneously, and adding all of that complexity to one graph leads to figures that can be difficult to interpret. Using facets we can display the same figure in different panels based on the values of a categorical variable. For example, instead of using different shapes for the different islands, we could use facet_wrap() function as below.\n\nggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) +   \n  geom_point() +\n  labs(title=\"Island comparision of flipper length and body mass by species\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") + \n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x') +\n  facet_wrap(~island)\n\n\n\n\n\n\n\n\nExercise: Try adding scales=\"free\" argument within facet_wrap() and see what happens. Would this be a useful figure if the purpose was to compare the different islands? Are there cases where it would be useful?"
  },
  {
    "objectID": "index.html#interactive-plots",
    "href": "index.html#interactive-plots",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.6 Interactive plots",
    "text": "7.6 Interactive plots\nThe plotly package provides functionality for making interactive plots that has tools for zooming in and out, panning, hovering and among others. While this package has many different ways to create these plots with different level of functionality, the simplest is the ggplotly() function which adds these tools to ggplots. This can be very useful for exploring data.\n\n# install and load the plotly package\n# install.package(\"plotly\") # delete the '#' to install\nlibrary(plotly)\n\nThere are two ways to run the ggplotly() function. First, simply wrap the ggplotly() function around the chain of functions used to make a ggplot.\n\nggplotly(\n  ggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) +   \n  geom_point() +\n  labs(title=\"Island comparision of flipper length and body mass by species\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") + \n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x')\n)\n\n\n\n\n\nThe other is to name the chain of functions and wrap that named object in the ggplotly() function\n\nfliplen_bodmass_plot &lt;-  ggplot(data = cleandat) +\n  aes(x = body_mass_g, y = flipper_length_mm, color = species) +   \n  geom_point() +\n  labs(title=\"Island comparision of flipper length and body mass by species\",\n       x = \"Body mass (g)\",\n       y = \"Flipper length (mm)\",\n       color = \"Species\") + \n  theme_bw() +\n  scale_colour_brewer(type = \"qual\", palette = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, formula = 'y ~ x')\n\nggplotly(fliplen_bodmass_plot)"
  },
  {
    "objectID": "index.html#exporting-plots-for-publication",
    "href": "index.html#exporting-plots-for-publication",
    "title": "Bring Your Own Data (BYOD) Series",
    "section": "7.7 Exporting plots for publication",
    "text": "7.7 Exporting plots for publication\nOne of the easiest way to save and export plots is to use the ggsave() function. Use the ?ggsave to obtain more information on how the function works. By default, the latest plot displayed will be saved, but if a previously displayed plot had been saved as an R object, the name of that R object can be specified to save that one instead of the last one. Options available here include dpi=..., width=... and height=... for our figure. This is where we can make the final adjustments depending if the plot is to be used in a powerpoint presentation, or a word document, for example.\nLet’s save one figure, and then play with these format options to see how it changes the appearance and quality of the exported image. Often it is by trial and errors that you will find the best format for your specific situation!\n\nggsave(\"outputs/penguins_data_exploration.jpg\",\n       plot = fliplen_bodmass_plot,\n       dpi = 300, height = 5, width = 7, units = \"in\")"
  }
]