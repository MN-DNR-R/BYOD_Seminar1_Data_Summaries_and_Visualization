---
title:    "Bring Your Own Data (BYOD) Series"
subtitle: "Summarizing and Visualizing your data in R"
author:   "MN-DNR Biometricians"
date:     today
engine:   knitr
format: 
  html: 
    highlight: tango
    css: camp_style.css
    number-sections: true
    fontsize: 14pt
    toc: true
    mainfont: Calibri
    monofont: Aptos Mono
---


```{r}
#| echo: false
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
```

```{css your_turn_callout}
#| echo: false
{
}
.YourTurn {
  margin:        0em;
  border:        2px solid #003865;
  border-left:   5px solid #003865; 
  border-radius: 10px;
}
.YourTurn-header {
  margin-left:   0em;
  margin-top:    0em;
  margin-bottom: 0em;
   /* align-items: center; */
   /* vertical-align: text-bottom; */
  padding-left:   10px;
  padding-top:    5px;
  padding-bottom: 0px;
  background-color: #0080A6;
  border: 2px solid #003865;
  border-left: 10px solid #003865; 
  border-bottom: 1px solid #003865; 
  border-top-right-radius: 10px;
  color: white;
  font-size: 1.3em;
  font-weight: bold;
  /* background-size: 25px;
  background-repeat: no-repeat;
  background-position: 10px center;
  background-image: url("fa-code-icon.png"); */
}
.YourTurn-container {
  border: 2px solid #003865;
  border-left: 10px solid #003865; 
  border-top: 1px solid #003865; 
  padding-top: 5px;
  padding-left: 10px;
  padding-right: 10px;
  padding-bottom: 5px;
  color: black;
  background-color: white;
  border-bottom-right-radius: 10px;
}
```


# Workshop goals

The goal of this workshop is to provide the tools and hands-on experience necessary so that participants are comfortable importing and tidying-up their data in R, creating summaries, and generating publication-quality figures. If time allows we could also explore simple statistical models during the practice section of the workshop. </p>

Throughout this workshop will use the syntax of the `tidyr` package, which offers an efficient way of coding and building complexity in data manipulation steps in an organized and structured way. 

The content presented in this document was inspired by some of the courses presented at [MDH R Camp](https://tidy-mn.github.io/R-camp-penguins/). We encourage all participants to  take a look at the material generously shared by MDH on that link, and watch some of the instructional videos.    

# Setting-up our work space!

Let's set up our work space for the day by first creating a new project for this workshop. All of the scripts and data used in the workshop should be saved to that project so that everything can be easily referenced in the future. </p>

We will now take a few moments to demonstrate how to set-up a new project. When that is done, let's create two new R scripts: 1) Penguins_data_demo.r, 2) Your-own-data.r script. You can chose the names that you want for these scripts; one will contain everything that we will demonstrate in this class with a dataset that we will provide (penguins!), and the other will contain the code that you will develop as you work with your own data. 

# Loading libraries and reading-in the data

In this section, we will learn about the different packages that we will be using in this workshop, and will explore different functions for reading files into r.  

```{r packages info,eval=T,message=F,echo=F}

library(tidyverse) 
library(kableExtra)

packages_info <- data.frame(
  Package = c("readr","readxl","tidyr","ggplot2","tidyverse"),
  Purpose = c("Read delimited files","Read excel files", 
             "Tidy messy data", 
             "Create elegant data visualisations using the grammar of graphics", 
             "Load the packages above and many others useful manipulating and visualizing data")
)

kable(packages_info, caption = "Essential R Packages for tidying and visualizing data") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

## Let's load packages and read-in data!

```{r eval=F}
# Load library
library(tidyverse) # this automatically loads readr, readxl, tidyr, etc.

# we can check what packages were loaded by running the following command line:
tidyverse_packages()
```
 
## Let's load a few datasets in different formats

```{r eval=F}
mydat_csv <- read_csv("data/penguin_data_final.csv") # load a .csv file into your R environment

mydat_xls <- read_excel("data/penguin_data_final.xlsx") # load a .xlsx file into your R environment

```

You can look in the environment and make sure that the files were loaded properly! We will also demonstrate ways to explore your data in the next section.  

## Now we are going to load the dataset for today's demonstration. 

The `palmerpenguins` package was created by Allison Horst, Alison Hill, and Kristen Gorman as a tool for teaching data manipulation and analysis techniques in R. In the following sections we will explore the data available within this package, and we will learn to manipulate and visualize the data using a variety of tools and techniques. Below you will use the `citation()` command line to get the full citation for the package!</p>

You also can read more about the package here: [PalmerPenguins](https://allisonhorst.github.io/palmerpenguins/)

```{r eval=F}

# install package (once you have installed the package you will not need to run that line)
install.packages("palmerpenguins")

# load library into your R environment. 
library(palmerpenguins)

# Get information about the palmerpenguins package:
?palmerpenguins

# Get proper citation for package if we were to be using this in publication. Note that you can use the "citation" function for any of the packages used in an analysis, which is very useful when writing the methods in a report or peer-reviewed manuscript. 

citation("palmerpenguins")

# The library contains two datasets which can be called without having to read them manually (as we previously did with the .csv or .xlsx files). One which contains raw penguins data (penguin_raw), and the second file (penguins) is the simplified (i.e., clean) dataset (penguins). 

# Let's simplify the name of this dataset for easier coding by creating a new object:
rawdat<-penguins_raw
```

# Getting to know your data

There are many functions available to explore the data, here is a list of the main ones that we will be using in this workshop. 

```{r useful functions,eval=T,message=F,echo=F}

useful_fct_1 <- data.frame(Function=c("glimpse(...)","str(...)","names(...)","head(...)","tail(...)","nrow(...)","ncol(...)","summary(...)","unique(...)"),Purpose = c("overview of dataframe rows, columns, column names, daraframe dimension, and a glimpse of first values", "Succinct summary of all columns of a dataframe; similar to glimpse but within base R","column names","display for n rows of data (default is 6)","displays last n rows of data (default is 6)","number of rows","number of columns","summary of the data in each column","displays unique values of a variable"))

kable(useful_fct_1, caption = "Useful functions for data exploration") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

## Data types (incomplete)


```{r data types,eval=T,echo=F,message=F}
data_types <- data.frame(Type=c("Numeric","Integer","Logical","Character"),"Exampe"=c("1.5, 2.6","1, 2","True/False","One, Two"))

kable(data_types, caption = "Data types supported in R") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```


## Let's first take a look at the data

```{r eval=F}
# the glimpse function provides a good first overview of the data. Function "str" produces something similar. 
glimpse(rawdat)

# extract column names
names(rawdat)

# look at first and last rows
head(rawdat,n=10)
tail(rawdat,10)

# How rows and columns do we have
nrow(rawdat)
ncol(rawdat)

# lists unique values; this gives an overview of the number of unique values in a dataframe, and can also help identifying if there are spelling mistakes or other data entry errors. 
unique(rawdat$Species)
unique(rawdat$Island)
unique(rawdat$Region)

unique(rawdat$`Individual ID`) # How many unique ID's do we have? How many data points do we have? Do they match?

# quick summary of all of the data
summary(rawdat)

```

## Data quality check

Looking at the raw data, what do you observe could be improved for facilitating some analyses and data visualizations? Is the dataset pretty clean and analysis-ready, or are these things that need to be addressed and changed so that we don't run into issues later in the process?

Here are some examples:

1. species names are long
2. some columns may not be necessary
3. individual ID is not unique
3. we may want columns that classify the data based on some criteria (e.g., a) heavy or light and b) long-, medium-, or short-billed).  

# Tidying your data

## What is tidy data?

We refer to "tidy data" as a dataset where each column is a variable, each row is an observation, and each cell contains a single value and a data type that is consistent across a given column (e.g., all numeric). The `tidyr` packages contains functions for manipulating the data so that we can create a clean, tidy dataset to-be-used for all analyses. </p>

**Note**: Recall that we will never overwrite the original dataset. The raw data should always remain in its original location and be kept unaltered. The beauty of R scripts is that we can save all data cleaning and data manipulation steps while retaining the original data.  

## Why is it important to tidy our data?

Taking time to tidy a dataset ensures that the data summaries, analyses, or visualizations we produce represent "true" data values to the best of our knowledge (e.g., no wrongly assigned missing data or data-entry related outliers). It is a the first and most critical step of any data analysis, and though it can be a lengthy process, it is worth the effort. 

## Why tidying data in R?

Using R and R scripts ensures that the original dataset is kept, and that all data manipulation steps are documented and reproducible. This is a major advantage of tidying data in R as opposed to using spreadsheet applications such as Excel, where there is often no to little track records of changes made to a dataset. </p>

## Introducing pipe operator

Ton increase efficiency, the tidyr library uses pipe operators .... 

## Let's clean-up some of those columns

```{r useful tidy function,echo=F}
useful_fct_2<-data.frame(Function=c("filter(...)","select(...)","arrange(...)","mutate(...)"),Purpose=c("keep (or exclude) rows that meet specific criteria","select columns to keep (or to drop)","sort a dataframe based on a column's value (or several columns' values)","add new columns or update existing columns"))

kable(useful_fct_2, caption = "Useful functions to create tidy data") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

### Formating variable names


```{r create tidy data, eval=F}
# Let's take a look at the data again
head(rawdat)
names(rawdat)

# lower column names
names(rawdat)<-tolower(names(rawdat))

names(rawdat)

# replace spaces; spaces in variable names are just slightly more complicated to code and it is much simpler not to have any spaces at all

names(rawdat)<-str_replace_all(names(rawdat)," ","_") # Note: str_replace_all is part of the stringr package, automatically loaded when we load tidyverse, but it could be loaded individually as well.

# further modify column names for simplicity
names(rawdat)<-str_replace_all(names(rawdat),"\\(|\\)","")
```


### Removing unecessary data, creating variables, and subsetting the dataset

```{r reduce dataset,eval=F}

# keep only columns of interest
cleandat <- rawdat %>% select(species,region,island,stage,clutch_completion,date_egg,flipper_length_mm,culmen_length_mm,body_mass_g,sex,comments) 

# if you wanted to remove one or severeal column it may be easier to do the following:
cleandat<- cleandat %>% select(!stage & !region) 

# remove scientific names in species
unique(cleandat$species)

cleandat$species<-str_replace(cleandat$species," \\(Pygoscelis adeliae\\)","")
cleandat$species<-str_replace(cleandat$species," \\(Pygoscelis papua\\)","")
cleandat$species<-str_replace(cleandat$species," \\(Pygoscelis antarctica\\)","")

unique(cleandat$species)

# Create unique record ID
penguins <- mutate(cleandat, 
                   unique_id = 1:n()) 
```

### Assessing usability of data

If it looks like some records may not be usable based on some criteria, it may be a good idea to create an indicator variable (yes/no) that identifies which record may not be usable for analysis. If needed, we can do this using the `mutate` and `case_when` functions. 

```{r eval=F}
# Let's look at the comments to assess if some data may not be usable for analysis.  
unique(cleandat$comments)

## Create an indicator variable for the "adult not sampled" comments so that we can easilly remove them from future analyses if needed.


cleandat <-cleandat %>% mutate(usable_adult_data=case_when(comments=="Adult not sampled."~"no",comments=="Adult not sampled. Nest never observed with full clutch."~"no",TRUE~"yes"))

# We can now filter-out that comment column as it will no longer be necessary for our work. 
cleandat <- cleandat %>% select(!comments)

```

### Creating new variables

We're getting close to having a dataset that will be easier to use for analysis! Now let's say we would like to create 1) a culmen to body mass index, 2) flipper group category based on flipper length, and 3) a factor variable that will identify if the penguins were small, medium, or large based on their weight. We can do both of these things again using the `mutate` and `case_when` functions. 

```{r eval=F}

## Create a culmen to body mass index
cleandat <- cleandat %>% mutate(body_mass_kg=body_mass_g/1000,culmen_bodymass_index=round(culmen_length_mm/body_mass_kg,2))

## Assign flipper lenght category; the TRUE statement means that anything not assigned to "big flips" will be assigned to "small flips" in that example. 
cleandat<-cleandat %>% 
    mutate(flipper_group = case_when(flipper_length_mm > 210 ~ "big flips",TRUE ~ "small flips" ))

## Oups!! We forgot to check if we had NAs in the data before converting to a group!
filter(cleandat,is.na(flipper_length_mm))

## Let's correct that mistake and re-create the groups while accounting for NAs first.
cleandat<-cleandat %>% 
    mutate(flipper_group = case_when(is.na(flipper_length_mm)~"unknown",flipper_length_mm > 210 ~ "big flips",TRUE ~ "small flips" ))

## Using that same logic, let's create another group absed on weight class, and let's make sure that we do not assign a class to missing data. 
cleandat<-cleandat %>% mutate(weight_class = case_when(is.na(body_mass_g)~"unknown",body_mass_g<=3500~"small",body_mass_g<4300~"medium",TRUE~"large"))

head(cleandat)
```




## Formatting dates and times 

### Below are some useful functions for dealing with dates and times

```{r useful date time functions,echo=F,eval=F}
useful_fct_3<-data.frame(Function=c("as_date(...)"),Purpose=c("format date ....))

kable(useful_fct_3, caption = "Useful functions to format dates and times") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

```

### To illustrate this, let's first add a "time" variable to our dataset

The time variable will be in seconds from 00:00:00. We will learn how to re-format this in proper time stamp (hour:minute:second) so that it is more intuitive to work with and visualize. Times in seconds frequently happen with GPS Location data, for example. It isn't a bad idea to have a way to convert them in our toolbox!

```{r eval=F}

# Define the start and end dates/times for the range of sampling times (in UTC, i.e., 3 hours ahead of the time zone where penguins were observed - see note below)
min_start_time <- 9*60*60 # 6 am in seconds from midnight
max_end_time <- 21*60*60 # 6 pm in seconds from midnight

# Create a sequence of all possible timestamps within the range, e.g., by 10 minute segments
full_time_sequence <- seq(min_start_time, max_end_time, 10*60)

# For each record, sample a random number from the full time sequence created above
cleandat <- cleandat %>% mutate(time_sec=sample(full_time_sequence,n(),replace=TRUE)) 

```

### Formatting dates and times

```{r eval=F}
# first set date as a set date
cleandat <- cleandat %>% mutate(date=as_date(date_egg))

# create a date and time variable. Note that although the palmer penguins dataset was collaected at the Palmer LTER in Antarctica, which is in UTC-03, data were collected in UTC times and will need to be converted to UTC-03.  
cleandat <- cleandat %>% mutate(date_time_utc=as.POSIXct(paste(as_date(date_egg,format="%Y-%m-%d"),"00:00:00",format="%Y-%m-%d %H:%M:%S"),tz="UTC")+time_sec)

# Convert to proper time zone UTC-03                                    
cleandat <- cleandat %>% mutate(date_time_utc03=as.POSIXct(format(date_time_utc,tz="Etc/GMT+3"),tz="Etc/GMT+3"))
                                    
# Note from R help file on time zones (https://stat.ethz.ch/R-manual/R-devel/library/base/html/timezones.html): "Most platforms support time zones of the form ‘⁠Etc/GMT+n⁠’ and ‘⁠Etc/GMT-n⁠’ (possibly also without prefix ‘⁠Etc/⁠’), which assume a fixed offset from UTC (hence no DST). Contrary to some expectations (but consistent with names such as ‘⁠PST8PDT⁠’), negative offsets are times ahead of (East of) UTC, positive offsets are times behind (West of) UTC."

```


### Extracting information from as.POSIXct object or variable

Now that we've formatted our date and time variable, we can extract all sorts of useful information very easily. 

```{r eval=F}

# study year
year(cleandat$date_time_utc03)

# creating a year coluymn in our dataframe
cleandat <- cleandat %>% mutate(year=year(date_time_utc03)) 

# we can extract all sorts of information, month, day, hour, minute, etc. from date time objects when they are formatted adequately

# Example of distribution of sampling hours across the dataset
hist(hour(cleandat$date_time_utc03)) #Pretty random, but these were also sampled randomly across the range of possible  times between 6 am and 6 pm! 

# Take a few minutes to experiment with some of these. 

```


# Creating data summaries

Creating data summaries is often the first step of a thorough Exploratory Data Analysis (EDA). The `group_by` and `summarize` functions are some of the most useful functions you'll find in R as they are very intuitive and efficient. </p>

We will summarize the penguin data to illustrate what can be done with these two functions. Let's first take a look at the data again using `glimpse` to refresh our memory on the class of data that we have on hand. </p>

We also will want to filter out the data we flagged as "unusable" during our data tidying exercise.

## Removing unusable and unecessary data to create our "working" dataset 

```{r eval=F}
# taking a look at the data
glimpse(cleandat)

# filtering out the unusable records
cleandat <- cleandat %>% filter(usable_adult_data!="no") # using the != syntax means "not equal to", so basically here we are saying that we are keeping everything that is not equal to "no", i.e., we are keeping the "yes"!

# cleandat contains columns which for simplicity we may want to remove
cleandat <- cleandat %>% select(!usable_adult_data & !time_sec & !date & !date_time_utc)

glimpse(cleandat) # Much better!!!

# Let's save our cleaned dataset
write_csv(cleandat,"data/clean_peanguindat.csv")

```

Let's compare flipper length and body mass across species. The `group_by` function allows summarizing information for one or multiple nested groups (e.g., species alone, or species within islands, etc.). The `summarize` function will allow creating summaries such as mean, standard deviation, sample size, for the groups we defined with the `group_by` function.</p>  

**Note**: If there are missing data in a column, the output of a summary will return NA unless it is specified that the NAs need to be ignored from the calculation.   

```{r read dat,eval=T,echo=F,message=F,warning=F}
# read cleandat created above; this chunk is for course developers only because we are not actually creating the script when running the report since it is to demonstrate and go over each command line with  participants. Dataset will thus be created in class, but we need to upload it if we want to print some of the summaries and graphs in lines of code that follow 
library(tidyverse)
cleandat<-read_csv("../data/clean_peanguindat.csv")

# cleandat<-read_csv("data/clean_peanguindat.csv") To read on individual computer 

```

### Summarizing flipper lengths

Let's first illustrate the tidyr syntax by creating a summary of flipper length by species. We can run this list of commands as they are, or create an R object if we wanted to store the summary using the `<-` syntax, e.g., `flipper_lt_summary <- cleandat %>% ...`. 

```{r, eval=F}
cleandat %>% 
  group_by(species) %>% 
  summarise(min_flipper_length=mean(flipper_length_mm,na.rm=T))

```

Summarizing means only may not be the most satistifying if one wanted to compare the means across species. We can combine functions in that same statement, and get a more complete summary of flipper length across species. 

```{r,summary table, echo=F,eval=T,include=T,message=F}
flipper_length_summary <- cleandat %>% 
  group_by(species) %>% 
  summarise(mean_flipper_length=mean(flipper_length_mm,na.rm=T),sd_flipper_length=sd(flipper_length_mm,na.rm=T),min_flipper_length=min(flipper_length_mm,na.rm=T),max_flipper_length=max(flipper_length_mm,na.rm=T),N=n())

kable(flipper_length_summary)

```

Above we created a summary of mean, standard deviation, mininmum, and maximum flipper length. There is no limit on the number of functions we can calculate with thing the `summarise` statement. </p>

But wait, we forgot to calculate the standard error which is a metric that we may need for calculating confidence intervals! You can use the `mutate` function to add that measure to the summary table previously created. 

```{r}
flipper_length_summary <- flipper_length_summary %>% 
  group_by(species) %>% 
mutate(se_flipper_length = sd_flipper_length/sqrt(N))

kable(flipper_length_summary)

```

**Exercise**: Let's say that we want to summarise flipper length by species AND island. Let's take a few minutes to try creating different summaries based on multiple grouping variables. </p>

**Hint**: the grouping variables can be added within that `group_by()` function separated by a `comma`. You can use the `names()` or `glimpse` function to remember the name of the different variables available to use. </p>

# Data visualization

Now that we have a clean dataset and have created useful summaries, we can now think of how to best visualize the data. We will be using the `ggplot2` package to demonstrate various data visualization options. While it is certainly possible to create high-quality figures in base R, ggplot2 provides a powerful way to create and customize figures in an intuitive way (after getting comfortable with the syntax and structure!).</p>

## Key Data Visualization principes (incomplete, need a few items here!)



## Main elements of a ggplot figure

Plots in `ggplot` are built as a series of layers sequentially added in an intuitive way. Let's think about how we would graph a figure by hand. First, we would think of the basic component or our figure or in other words the things that we want to represent (i.e., the **data**). We would then think of what specifically do we want to represent (i.e., **The Xs, the Ys, etc.**), and how (i.e., **the type of image**). `ggplot` uses this logic to sequentially add complexity and layers to plots wiht limitless options.</> 

Below are the main elements of a plot built in ggplot:

```{r elements of ggplot, eval=T,echo=F,message=F}
ggplot_elements<-data.frame("Element"=c("Basics","Aesthetics","Geometry","Labels and legents","Themes","Scales","Faceting","Statistics","Coordinate systems"),"Definition"=c("Data to be mapped","aesthetics of the graph such as X and Y (if more then one variable),grouping variables, or colours or shape","Defines the type of plot","Axis and legend labels","Define the appearance of the plot","Scales for the X and Y axis","Divides the plot into subplots","Builds new variables (e.g., regression line) to plot","Defines the relationship between X and Y"))

kable(ggplot_elements, caption = "Elements of a plot done in ggplot") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

For each of these elements, you can find a detailed description on the [ggplot2 cheatsheet](https://rstudio.github.io/cheatsheets/data-visualization.pdf). We will give some examples of the types of figures that we can do in ggplot, and how to add layers and complexity without having to add so many lines of code that it becomes cumbersome! Let's explore some of the syntax using examples for one variable and two variables. 

## One-variable figures

Recall the penguin dataset and how the data is structured. 

```{r,eval=T}
glimpse(cleandat)
```

We may want to visualize the number of records that we have for each of the islands. Let's first set up the basics, or canvas, for our plot and specify the data. 

```{r eval=T,message=T,echo=T}
ggplot(data=cleandat)
```

This is pretty much a blank slate on which we can add `aesthetics` (what is it that we want to show on our figure?). Let's first take a look at the list of possible `aesthetics`. 

```{r, eval=T,message=F,echo=F}
aes_options <- data.frame("Aesthetics"=c("x =","y =","size =","alpha =", "fill =", "colour =","shape ="),"Description"=c("Variable to be plotted on the X axis","Variable to be plotted on the Y axis","Size of the point, column or line","Transparency of the object","The fill colour of a column area","The colour for points and lines, or the outline colour for columns and areas","The shape of the point when making a scatter plot"))

kable(aes_options, caption = "Options to be passed into the `aes` statement") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We add different elements to the blank canvas using the **plus** sign. Let's count how many records we have per island in our cleaned dataset. **Island** will thus be on the **x axis**, which is our only variable in this plot. 

```{r eval=T,echo=T,message=F}
ggplot(data=cleandat)+aes(x=island)
```

Adding `aes(x=island)` simply added the X axis to our blank canvas. We can now fill it by specifying the type of plot that we want to make with this. For simply visualizing the number of records per island we will do a barchar, which we specify using one of the available `geometries` as noted on the [ggplot2 cheatsheet](https://rstudio.github.io/cheatsheets/data-visualization.pdf). 

```{r eval=T,echo=T,message=F}
ggplot(data=cleandat)+ # blank canvas
  aes(x=island)+ # define the X axis
  geom_bar() # type of graph
```

We're off to a great start! But this figure could show more information, such as the number of records for each species on each of these islands. Recall the description of the `aesthetics` options,one being **fill** which can indicate the fill colour of the bar based on a categorical variable.  

```{r eval=T,echo=T,message=F}
ggplot(data=cleandat)+
  aes(x=island, fill=species)+ # species will be in colour, island will be on the X axis
  geom_bar() # type of graph
```

Let's add labels and make the graph look a little bit nice by removing the grey background colour. Labels can be added using the `labs` syntax, and the `theme` can be adjusted to change the overall appearance of the figure.  

```{r eval=T,echo=T,message=F}
ggplot(data=cleandat)+
  aes(x=island, fill=species)+ # species will be in colour, island will be on the X axis
  geom_bar()+ # type of graph
labs(title="Distribution of penguin species per island in the Palmer penguins clean dataset",x="Island",y="Number of penguins",fill="Species")+ #Customizing labels; "fill="Species" will change the legend title for the fill aesthetics 
  theme_bw() # remove grey background
```

This figure is starting to look pretty good! You can spend time exploring different themes and taking a look at what the output looks like. An additional thing that we can do is adjust the colour. We can use the function `scale_fill_brewer` to pick a different colour scheme. The available colour palettes can be viewed in [RColorBrewer palette](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3). This tools offers an opportunity to select only colours that are colorblind safe or printer friendly, among other things. 

```{r eval=T,echo=T,message=F}
ggplot(data=cleandat)+
  aes(x=island, fill=species)+ # species will be in colour, island will be on the X axis
  geom_bar()+ # type of graph
labs(title="Distribution of penguin species per island in the Palmer penguins clean dataset",x="Island",y="Number of penguins",fill="Species")+ #Customizing labels; "fill="Species" will change the legend title for the fill aesthetics 
  theme_bw()+ # remove grey background
scale_fill_brewer(type="qual",palette=3)
```

Often it is more desirable to look at bars that aren't stacked but that are side-by-side. The `position` of the bars can be adjusted within the ``geom_bar()`` statement. Let's add this to our figure above (since it looks so nice already!) with a simple addition withih the parentheses of `geom_bar()`.

```{r eval=T,echo=T,message=F}
ggplot(data=cleandat)+
  aes(x=island, fill=species)+ # species will be in colour, island will be on the X axis
  geom_bar(position=position_dodge(preserve="single"))+ # type of graph
labs(title="Distribution of penguin species per island in the Palmer penguins clean dataset",x="Island",y="Number of penguins",fill="Species")+ #Customizing labels; "fill="Species" will change the legend title for the fill aesthetics 
  theme_bw()+ # remove grey background
scale_fill_brewer(type="qual",palette=3)
```

**Exercise**: Now it is your turn to play with single-variable plots! Refer to the [ggplot2 cheatsheet](https://rstudio.github.io/cheatsheets/data-visualization.pdf) and try making a histogram of the penguins body weights to see how the weights are distributed across the dataset overall. In a second time, add complexity to this figure by visualizing how the distribution of body weight varies across species! Hint: if the species-specific bars are overlapping, you can add transparency using the `alpha` statement within the geometry function.   

```{r,eval=F,echo=F,message=F}
ggplot(data=cleandat)+
  aes(x=body_mass_g, fill=species)+ # species will be in colour, island will be on the X axis
  geom_histogram(alpha=0.65)+
  scale_fill_brewer(type="qual",palette=3)+
  theme_bw()
```

As you can see, the options are limitless!

## Two-variables figures

In most instances we want to show relationships between two variables, sometimes also show how that relationship varies across groups. We will demonstrate this with the penguin dataset by building a figure of the relationship between penguins flipper length and body mass.</p>

We've already seen how to build a figure from the basic level (data only) to a nice figure with labels, titles, and better colours, so we can go ahead and build a nice scatterplot right away. The geometry to use in that instance will be `geom_point()` instead of `geom_bar()`. Here will have a **X** and a **Y** variable to pass to the `aes()` function. 

```{r }
ggplot(data=cleandat)+
  aes(x=body_mass_g,y=flipper_length_mm)+ 
  geom_point()+ # type of graph
labs(title="Relationship between flipper length and body mass",x="Body mass (g)",y="Flipper length (mm)")+ #Customizing labels
  theme_bw() # remove grey background
```

Above we see the relationship using the whole dataset. We could follow a similar approach as above to show how that relationship varies across species. We could use different colours and/or different shapes to highly species-specific patterns. Let's experiment with this and use the same colour palette as above!

```{r,echo=T,message=F,warning=FALSE}
ggplot(data=cleandat)+
  aes(x=body_mass_g,y=flipper_length_mm,colour=species)+ 
  geom_point()+ # type of graph
labs(title="Species-specific relationship between flipper length and body mass",x="Body mass (g)",y="Flipper length (mm)",colour="Species")+ #Customizing labels
  theme_bw()+ # remove grey background
  scale_colour_brewer(type="qual",palette=3)
```

Interesting! Intuitively our eyes are trying to draw regression lines through the cloud of points. It is possible to add these lines on the figure using the `geom_smooth` function. 

```{r,echo=T,message=F,warning=FALSE}
ggplot(data=cleandat)+
  aes(x=body_mass_g,y=flipper_length_mm,colour=species)+ 
  geom_point()+ # type of graph
labs(title="Relationship between flipper length and body mass by species",x="Body mass (g)",y="Flipper length (mm)",colour="Species")+ #Customizing labels
  theme_bw()+ # remove grey background
  scale_colour_brewer(type="qual",palette=3)+
  geom_smooth(method="lm",se=FALSE) # se=T would show confidence limits based on the standard error. The colour follows the same as the cloud of points and does not need to be added again here.
```

If you would like you can take a moment to play with other variables and make additional figures. Also note that this is a pretty clean dataset and straight regression lines seem to fit pretty well. This isn't always the case, however, and the figures do not replace thorough statistical tests and models!</p>

**Exercise**: Repeat the same figure as above but show `species` as different colours and `islands` as different shapes. What do you notice?

## Facets!

At times we may want to display complex information for several categories simultaneously, and adding all of that complexity to one graph leads to figures that can be difficult to interpret. Using `facets` we can display the same figure in different panels based on the values of a categorical variable. For example, instead of using different shapes for the different islands, we could use `facet_wrap()` function as below.


```{r,echo=T,message=F,warning=FALSE}
ggplot(data=cleandat)+
  aes(x=body_mass_g,y=flipper_length_mm,colour=species)+ 
  geom_point()+ # type of graph
labs(title="Island comparision of the relationship between flipper length and body mass by species",x="Body mass (g)",y="Flipper length (mm)",colour="Species")+ #Customizing labels
  theme_bw()+ # remove grey background
  scale_colour_brewer(type="qual",palette=3)+
  geom_smooth(method="lm",se=FALSE)+ # se=T would show confidence limits based on the standard error. The colour follows the same as the cloud of points and does not need to be added again here.
facet_wrap(~island)
```

**Exercise**: Try adding the `scales="free"` argument within `the` facet_wrap() and see what happens. Would this be a useful figure if the purpose was to compare the different islands? Are there cases where it would be useful?  </p>

## Customizing plot options (incomplete, need to add text modif and point size, etc.)

```{r,echo=T,message=F,warning=FALSE}
ggplot(data=cleandat)+
  aes(x=body_mass_g,y=flipper_length_mm,colour=species)+ 
  geom_point()+ # type of graph
labs(title="Island comparision of the relationship between flipper length and body mass by species",x="Body mass (g)",y="Flipper length (mm)",colour="Species")+ #Customizing labels
  theme_bw()+ # remove grey background
  scale_colour_brewer(type="qual",palette=3)+
  geom_smooth(method="lm",se=FALSE)+ # se=T would show confidence limits based on the standard error. The colour follows the same as the cloud of points and does not need to be added again here.
facet_wrap(~island)
```




## Exporting datasets in nice format for publication

One of the easiest way to save and export plots is to use the `ggsave` function. Use the `?ggsave` to obtain more information on how the function works. By default, the latest plot displayed will be saved, but if a previously-displayed plot had been saved as an R object, the name of that R object can be specified to save that one instead of the last one. Options available here include `dpi=...`, `width=...` and `height=...` for our figure. This is where we can make the final adjustments depending if the plot is to be used in a powerpoint presentation, or a word document, for example.  </p>

Let's save one figure, and then play with these format options to see how it changes the appearance and quality of the exported image. 

```{r,echo=T,message=F,warning=FALSE}
getwd() # To remind yourself of the current working directory. Plots will be saved in that directory unless specified otherwise

ggsave("../outputs/penguins_data_exploration.jpg",plot=last_plot(),dpi=300,height=5,width=7,units = "in") 

```

# Conclusion (incomplete)


# Useful cheatsheets

[ggplot2](https://rstudio.github.io/cheatsheets/data-visualization.pdf)

[dplyr](https://nyu-cdsc.github.io/learningr/assets/data-transformation.pdf)

[tidyr](https://rstudio.github.io/cheatsheets/tidyr.pdf)


# Additional resources

[More on tidy data](https://tidyr.tidyverse.org/articles/tidy-data.html)

[More on ggplot2](https://ggplot2.tidyverse.org/)

[Key principes of effective data visualization](https://www.sciencedirect.com/science/article/pii/S2666389920301896)

